{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Esplorazione Dataset Industrial IoT\n",
    "\n",
    "Questo notebook esplora il dataset dei dispositivi IoT industriali per comprendere:\n",
    "- Struttura e caratteristiche dei dati\n",
    "- Distribuzione delle variabili\n",
    "- Correlazioni tra features\n",
    "- Identificazione di outliers e missing values\n",
    "- Analisi per tipo di dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import delle librerie necessarie\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configurazione per i grafici\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento configurazione\n",
    "with open('../config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "print(\"Configurazione caricata:\")\n",
    "print(f\"- Dataset path: {config['data']['raw_data_path']}\")\n",
    "print(f\"- Algoritmo selezionato: {config['model']['algorithm']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento del dataset\n",
    "data_path = config['data']['raw_data_path']\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset caricato con successo!\")\n",
    "print(f\"Forma del dataset: {df.shape}\")\n",
    "print(f\"Memoria utilizzata: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analisi Strutturale del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informazioni generali sul dataset\n",
    "print(\"=== INFORMAZIONI DATASET ===\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Prime righe del dataset\n",
    "print(\"\\n=== PRIME 5 RIGHE ===\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi delle colonne\n",
    "print(\"=== ANALISI COLONNE ===\")\n",
    "print(f\"Numero totale di colonne: {len(df.columns)}\")\n",
    "print(f\"\\nColonne numeriche: {df.select_dtypes(include=[np.number]).columns.tolist()}\")\n",
    "print(f\"\\nColonne categoriche: {df.select_dtypes(include=['object']).columns.tolist()}\")\n",
    "\n",
    "# Tipi di dati\n",
    "print(\"\\n=== TIPI DI DATI ===\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype} - Valori unici: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi dei valori mancanti\n",
    "print(\"=== VALORI MANCANTI ===\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Colonna': missing_data.index,\n",
    "    'Valori Mancanti': missing_data.values,\n",
    "    'Percentuale': missing_percent.values\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Valori Mancanti'] > 0].sort_values('Valori Mancanti', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualizzazione valori mancanti\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=missing_df, x='Colonna', y='Percentuale')\n",
    "    plt.title('Percentuale di Valori Mancanti per Colonna')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\nelse:\n",
    "    print(\"✅ Nessun valore mancante trovato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analisi dei Tipi di Dispositivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuzione dei tipi di macchine\n",
    "print(\"=== DISTRIBUZIONE TIPI DI DISPOSITIVI ===\")\n",
    "machine_counts = df['Machine_Type'].value_counts()\n",
    "print(f\"Numero di tipi di dispositivi diversi: {df['Machine_Type'].nunique()}\")\n",
    "print(\"\\nTop 10 dispositivi più comuni:\")\n",
    "display(machine_counts.head(10))\n",
    "\n",
    "# Visualizzazione distribuzione\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "machine_counts.head(15).plot(kind='bar')\n",
    "plt.title('Top 15 Tipi di Dispositivi')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(machine_counts.head(10).values, labels=machine_counts.head(10).index, autopct='%1.1f%%')\n",
    "plt.title('Top 10 Dispositivi - Distribuzione Percentuale')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificazione dispositivi secondo le specifiche del progetto\n",
    "devices_common_only = ['3D_Printer', 'AGV', 'Automated_Screwdriver', 'CMM', 'Carton_Former', 'Compressor', 'Conveyor_Belt', 'Crane', 'Dryer', 'Forklift_Electric', 'Grinder', 'Labeler', 'Mixer', 'Palletizer', 'Pick_and_Place', 'Press_Brake', 'Pump', 'Robot_Arm', 'Shrink_Wrapper', 'Shuttle_System', 'Vacuum_Packer', 'Valve_Controller', 'Vision_System', 'XRay_Inspector']\n", "\n",
    "# Dispositivi con caratteristiche aggiuntive\n",
    "laser_devices = ['Laser_Cutter']\n",
    "hydraulic_devices = ['Hydraulic_Press', 'Injection_Molder']\n",
    "coolant_devices = ['CNC_Lathe', 'CNC_Mill', 'Industrial_Chiller']\n",
    "heat_devices = ['Boiler', 'Furnace', 'Heat_Exchanger']\n",
    "\n",
    "# Classificazione\n",
    "def classify_device(machine_type):\n",
    "    if machine_type in devices_common_only:\n",
    "        return 'Solo Comuni'\n",
    "    elif machine_type in laser_devices:\n",
    "        return 'Laser'\n",
    "    elif machine_type in hydraulic_devices:\n",
    "        return 'Idraulico'\n",
    "    elif machine_type in coolant_devices:\n",
    "        return 'Refrigerante'\n",
    "    elif machine_type in heat_devices:\n",
    "        return 'Calore'\n",
    "    else:\n",
    "        return 'Altro'\n",
    "\n",
    "df['Device_Category'] = df['Machine_Type'].apply(classify_device)\n",
    "\n",
    "print(\"=== CLASSIFICAZIONE DISPOSITIVI ===\")\n",
    "category_counts = df['Device_Category'].value_counts()\n",
    "display(category_counts)\n",
    "\n",
    "# Visualizzazione\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='Device_Category', order=category_counts.index)\n",
    "plt.title('Distribuzione Categorie di Dispositivi')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analisi delle Variabili Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi della variabile target binaria\n",
    "print(\"=== ANALISI FAILURE_WITHIN_7_DAYS ===\")\n",
    "failure_dist = df['Failure_Within_7_Days'].value_counts()\n",
    "failure_percent = df['Failure_Within_7_Days'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Distribuzione:\")\n",
    "for val, count, perc in zip(failure_dist.index, failure_dist.values, failure_percent.values):\n",
    "    print(f\"  {val}: {count} ({perc:.2f}%)\")\n",
    "\n",
    "# Analisi della vita rimanente\n",
    "print(\"\\n=== ANALISI REMAINING_USEFUL_LIFE_DAYS ===\")\n",
    "life_stats = df['Remaining_Useful_Life_days'].describe()\n",
    "display(life_stats)\n",
    "\n",
    "# Visualizzazioni\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Distribuzione failure entro 7 giorni\n",
    "axes[0,0].pie(failure_dist.values, labels=['No Failure', 'Failure'], autopct='%1.1f%%', startangle=90)\n",
    "axes[0,0].set_title('Distribuzione Guasti Entro 7 Giorni')\n",
    "\n",
    "# Distribuzione vita rimanente\n",
    "axes[0,1].hist(df['Remaining_Useful_Life_days'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0,1].set_title('Distribuzione Vita Rimanente (giorni)')\n",
    "axes[0,1].set_xlabel('Giorni')\n",
    "axes[0,1].set_ylabel('Frequenza')\n",
    "\n",
    "# Boxplot vita rimanente per categoria failure\n",
    "sns.boxplot(data=df, x='Failure_Within_7_Days', y='Remaining_Useful_Life_days', ax=axes[1,0])\n",
    "axes[1,0].set_title('Vita Rimanente vs Failure Entro 7 Giorni')\n",
    "\n",
    "# Distribuzione vita rimanente per categoria dispositivo\n",
    "df.groupby('Device_Category')['Remaining_Useful_Life_days'].mean().plot(kind='bar', ax=axes[1,1])\n",
    "axes[1,1].set_title('Vita Rimanente Media per Categoria Dispositivo')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analisi delle Features Comuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiche descrittive delle features comuni\n",
    "common_features = ['Installation_Year', 'Operational_Hours', 'Temperature_C', 'Vibration_mms', 'Sound_dB', 'Oil_Level_pct', 'Coolant_Level_pct', 'Power_Consumption_kW', 'Last_Maintenance_Days_Ago', 'Maintenance_History_Count', 'Failure_History_Count', 'AI_Supervision', 'Error_Codes_Last_30_Days', 'AI_Override_Events']\n",
    "print(\"=== STATISTICHE FEATURES COMUNI ===\")\n",
    "common_stats = df[common_features].describe()\n",
    "display(common_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione distribuzioni features comuni\n",
    "n_cols = 4\n",
    "n_rows = (len(common_features) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "\n",
    "for i, feature in enumerate(common_features):\n",
    "    if i < len(axes):\n",
    "        axes[i].hist(df[feature].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[i].set_title(f'Distribuzione {feature}')\n",
    "        axes[i].set_xlabel(feature)\n",
    "        axes[i].set_ylabel('Frequenza')\n",
    "\n",
    "# Nascondere assi non utilizzati\n",
    "for i in range(len(common_features), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice di correlazione features comuni\n",
    "print(\"=== MATRICE DI CORRELAZIONE FEATURES COMUNI ===\")\n",
    "correlation_matrix = df[common_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Matrice di Correlazione - Features Comuni')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlazioni più forti\n",
    "correlation_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.5:\n",
    "            correlation_pairs.append({\n",
    "                'Feature_1': correlation_matrix.columns[i],\n",
    "                'Feature_2': correlation_matrix.columns[j],\n",
    "                'Correlazione': corr_val\n",
    "            })\n",
    "\n",
    "if correlation_pairs:\n",
    "    print(\"\\nCorrelazioni forti (|r| > 0.5):\")\n",
    "    corr_df = pd.DataFrame(correlation_pairs).sort_values('Correlazione', key=abs, ascending=False)\n",
    "    display(corr_df)\nelse:\n",
    "    print(\"\\nNessuna correlazione forte trovata tra le features comuni.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analisi Features Aggiuntive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi features aggiuntive\n",
    "additional_features = ['Laser_Intensity', 'Hydraulic_Pressure_bar', 'Coolant_Flow_L_min', 'Heat_Index']\n",
    "\n",
    "print(\"=== ANALISI FEATURES AGGIUNTIVE ===\")\n",
    "for feature in additional_features:\n",
    "    if feature in df.columns:\n",
    "        non_null_count = df[feature].notna().sum()\n",
    "        null_count = df[feature].isna().sum()\n",
    "        print(f\"\\n{feature}:\")\n",
    "        print(f\"  Valori non nulli: {non_null_count} ({non_null_count/len(df)*100:.1f}%)\")\n",
    "        print(f\"  Valori nulli: {null_count} ({null_count/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        if non_null_count > 0:\n",
    "            stats = df[feature].describe()\n",
    "            print(f\"  Media: {stats['mean']:.2f}\")\n",
    "            print(f\"  Deviazione standard: {stats['std']:.2f}\")\n",
    "            print(f\"  Min: {stats['min']:.2f}\")\n",
    "            print(f\"  Max: {stats['max']:.2f}\")\n",
    "\n",
    "# Visualizzazione features aggiuntive\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(additional_features):\n",
    "    if feature in df.columns and i < 4:\n",
    "        feature_data = df[feature].dropna()\n",
    "        if len(feature_data) > 0:\n",
    "            axes[i].hist(feature_data, bins=30, edgecolor='black', alpha=0.7)\n",
    "            axes[i].set_title(f'Distribuzione {feature}')\n",
    "            axes[i].set_xlabel(feature)\n",
    "            axes[i].set_ylabel('Frequenza')\n",
    "        else:\n",
    "            axes[i].text(0.5, 0.5, f'Nessun dato\\nper {feature}', \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].set_title(f'{feature} - Nessun Dato')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analisi degli Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificazione outliers usando il metodo IQR\n",
    "def identify_outliers(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "print(\"=== ANALISI OUTLIERS (METODO IQR) ===\")\n",
    "outlier_summary = []\n",
    "\n",
    "numeric_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Rimuovere le colonne ID e categoriche\n",
    "numeric_features = [f for f in numeric_features if f not in ['Machine_ID', 'Failure_Within_7_Days']]\n",
    "\n",
    "for feature in numeric_features[:10]:  # Analizzare prime 10 features\n",
    "    outliers, lower, upper = identify_outliers(df, feature)\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_percent = (outlier_count / len(df)) * 100\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': feature,\n",
    "        'Outliers': outlier_count,\n",
    "        'Percentuale': outlier_percent,\n",
    "        'Lower_Bound': lower,\n",
    "        'Upper_Bound': upper\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary).sort_values('Percentuale', ascending=False)\n",
    "display(outlier_df)\n",
    "\n",
    "# Visualizzazione boxplot per features con più outliers\n",
    "top_outlier_features = outlier_df.head(6)['Feature'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(top_outlier_features):\n",
    "    sns.boxplot(data=df, y=feature, ax=axes[i])\n",
    "    axes[i].set_title(f'Boxplot {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analisi delle Relazioni con il Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlazione features numeriche con il target\n",
    "print(\"=== CORRELAZIONE CON IL TARGET (FAILURE_WITHIN_7_DAYS) ===\")\n",
    "\n",
    "target_correlations = []\n",
    "for feature in numeric_features:\n",
    "    corr = df[feature].corr(df['Failure_Within_7_Days'])\n",
    "    if not np.isnan(corr):\n",
    "        target_correlations.append({\n",
    "            'Feature': feature,\n",
    "            'Correlazione': corr\n",
    "        })\n",
    "\n",
    "target_corr_df = pd.DataFrame(target_correlations).sort_values('Correlazione', key=abs, ascending=False)\n",
    "display(target_corr_df.head(10))\n",
    "\n",
    "# Visualizzazione correlazioni\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = target_corr_df.head(10)\n",
    "colors = ['red' if x < 0 else 'green' for x in top_features['Correlazione']]\n",
    "plt.barh(top_features['Feature'], top_features['Correlazione'], color=colors, alpha=0.7)\n",
    "plt.title('Top 10 Correlazioni con Failure_Within_7_Days')\n",
    "plt.xlabel('Correlazione')\n",
    "plt.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi differenze tra gruppi (failure vs no failure)\n",
    "print(\"=== CONFRONTO GRUPPI: FAILURE VS NO FAILURE ===\")\n",
    "\n",
    "failure_group = df[df['Failure_Within_7_Days'] == 1]\n",
    "no_failure_group = df[df['Failure_Within_7_Days'] == 0]\n",
    "\n",
    "# Confronto statistiche\n",
    "comparison_results = []\n",
    "for feature in target_corr_df.head(8)['Feature']:  # Top 8 features\n",
    "    failure_mean = failure_group[feature].mean()\n",
    "    no_failure_mean = no_failure_group[feature].mean()\n",
    "    \n",
    "    # Test t per differenza delle medie\n",
    "    from scipy.stats import ttest_ind\n",
    "    t_stat, p_value = ttest_ind(failure_group[feature].dropna(), \n",
    "                               no_failure_group[feature].dropna())\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Feature': feature,\n",
    "        'Failure_Mean': failure_mean,\n",
    "        'No_Failure_Mean': no_failure_mean,\n",
    "        'Differenza': failure_mean - no_failure_mean,\n",
    "        'P_Value': p_value\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "display(comparison_df)\n",
    "\n",
    "# Visualizzazione confronti\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(comparison_df['Feature']):\n",
    "    data_to_plot = [no_failure_group[feature].dropna(), failure_group[feature].dropna()]\n",
    "    axes[i].boxplot(data_to_plot, labels=['No Failure', 'Failure'])\n",
    "    axes[i].set_title(f'{feature}')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusioni e Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RIEPILOGO ANALISI ESPLORATIVA ===\")\n",
    "print(f\"\\n1. STRUTTURA DATASET:\")\n",
    "print(f\"   - Totale record: {len(df):,}\")\n",
    "print(f\"   - Totale features: {len(df.columns)}\")\n",
    "print(f\"   - Tipi di dispositivi: {df['Machine_Type'].nunique()}\")\n",
    "print(f\"   - Memoria utilizzata: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\n2. DISTRIBUZIONE TARGET:\")\n",
    "failure_rate = df['Failure_Within_7_Days'].mean() * 100\n",
    "print(f\"   - Tasso di failure entro 7 giorni: {failure_rate:.2f}%\")\n",
    "print(f\"   - Vita rimanente media: {df['Remaining_Useful_Life_days'].mean():.1f} giorni\")\n",
    "print(f\"   - Vita rimanente mediana: {df['Remaining_Useful_Life_days'].median():.1f} giorni\")\n",
    "\n",
    "print(f\"\\n3. QUALITÀ DATI:\")\n",
    "total_missing = df.isnull().sum().sum()\n",
    "missing_percent = (total_missing / (len(df) * len(df.columns))) * 100\n",
    "print(f\"   - Valori mancanti totali: {total_missing} ({missing_percent:.2f}%)\")\n",
    "\n",
    "print(f\"\\n4. FEATURES PIÙ CORRELATE CON IL TARGET:\")\n",
    "for i, row in target_corr_df.head(5).iterrows():\n",
    "    print(f\"   - {row['Feature']}: {row['Correlazione']:.3f}\")\n",
    "\n",
    "print(f\"\\n5. RACCOMANDAZIONI PER IL PREPROCESSING:\")\n",
    "print(f\"   - Il dataset sembra ben strutturato con pochi valori mancanti\")\n",
    "print(f\"   - Presenza di outliers da gestire in fase di preprocessing\")\n",
    "print(f\"   - Features aggiuntive hanno molti valori nulli (da gestire per tipo dispositivo)\")\n",
    "print(f\"   - Il target è moderatamente bilanciato ({failure_rate:.1f}% failure rate)\")\n",
    "print(f\"   - Alcune features mostrano correlazioni significative con il target\")\n",
    "\n",
    "# Salvataggio risultati esplorazione\n",
    "exploration_results = {\n",
    "    'dataset_shape': df.shape,\n",
    "    'failure_rate': failure_rate,\n",
    "    'missing_data_percent': missing_percent,\n",
    "    'top_correlated_features': target_corr_df.head(10).to_dict('records'),\n",
    "    'device_categories': df['Device_Category'].value_counts().to_dict(),\n",
    "    'outlier_summary': outlier_df.to_dict('records')\n",
    "}\n",
    "\n",
    "import json\n",
    "os.makedirs('data/processed', exist_ok=True)",
    "with open('data/processed/exploration_results.json', 'w') as f:\n",
    "    json.dump(exploration_results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n✅ Risultati dell'esplorazione salvati in 'exploration_results.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3",
   "version": "3.8.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}