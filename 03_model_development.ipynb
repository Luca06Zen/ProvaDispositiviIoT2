{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ Sviluppo Modelli di Machine Learning\n",
        "## Predizione Guasti Dispositivi IoT Industriali\n",
        "\n",
        "### Obiettivi:\n",
        "- Sviluppare e confrontare diversi algoritmi di machine learning\n",
        "- Ottimizzare iperparametri dei modelli migliori\n",
        "- Selezionare il modello finale per la produzione\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import delle librerie necessarie\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Librerie per machine learning\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
        "    accuracy_score, precision_score, recall_score, f1_score\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è XGBoost non disponibile. Installare con: pip install xgboost\")\n",
        "    XGBOOST_AVAILABLE = False\n",
        "\n",
        "import joblib\n",
        "import os\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Configurazione visualizzazioni\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "# Configurazione pandas\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Caricamento Dati Preprocessati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Caricamento dei dati preprocessati\n",
        "try:\n",
        "    # Tenta di caricare i dati dalla cartella data/processed\n",
        "    train_data = pd.read_csv('data/processed/train_data.csv')\n",
        "    test_data = pd.read_csv('data/processed/test_data.csv')\n",
        "    print(\"‚úÖ Dati caricati da data/processed/\")\n",
        "except FileNotFoundError:\n",
        "    # Se non trova i file, carica i dati puliti e crea train/test split\n",
        "    try:\n",
        "        df = pd.read_csv('data/processed/cleaned_data.csv')\n",
        "        print(\"üìä Caricamento dati puliti e creazione train/test split\")\n",
        "        \n",
        "        # Separazione features e target\n",
        "        X = df.drop('Failure_Within_7_Days', axis=1)\n",
        "        y = df['Failure_Within_7_Days']\n",
        "        \n",
        "        # Train/test split stratificato\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "        \n",
        "        # Creazione dei dataframe\n",
        "        train_data = pd.concat([X_train, y_train], axis=1)\n",
        "        test_data = pd.concat([X_test, y_test], axis=1)\n",
        "        \n",
        "        # Salvataggio per uso futuro\n",
        "        os.makedirs('data/processed', exist_ok=True)\n",
        "        train_data.to_csv('data/processed/train_data.csv', index=False)\n",
        "        test_data.to_csv('data/processed/test_data.csv', index=False)\n",
        "        \n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ùå Errore: Eseguire prima 02_data_preprocessing.ipynb\")\n",
        "        raise\n",
        "\n",
        "print(f\"üìä Training set: {train_data.shape}\")\n",
        "print(f\"üìä Test set: {test_data.shape}\")\n",
        "print(f\"üéØ Distribuzione target (train): {train_data['Failure_Within_7_Days'].value_counts().to_dict()}\")\n",
        "\n",
        "# Visualizza le prime righe\n",
        "print(\"\\nüìã Prime 5 righe del training set:\")\n",
        "display(train_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Preparazione Features e Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separazione features e target\n",
        "X_train = train_data.drop('Failure_Within_7_Days', axis=1)\n",
        "y_train = train_data['Failure_Within_7_Days']\n",
        "X_test = test_data.drop('Failure_Within_7_Days', axis=1)\n",
        "y_test = test_data['Failure_Within_7_Days']\n",
        "\n",
        "print(\"üîß Preparazione features:\")\n",
        "print(f\"   Features disponibili: {X_train.shape[1]}\")\n",
        "print(f\"   Campioni training: {X_train.shape[0]}\")\n",
        "print(f\"   Campioni test: {X_test.shape[0]}\")\n",
        "\n",
        "# Mostra le features disponibili\n",
        "print(f\"\\nüìã Features disponibili ({len(X_train.columns)}):\")\n",
        "for i, col in enumerate(X_train.columns, 1):\n",
        "    print(f\"   {i:2d}. {col}\")\n",
        "\n",
        "# Identificazione features numeriche e categoriche\n",
        "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f\"\\nüî¢ Features numeriche: {len(numeric_features)}\")\n",
        "print(f\"üè∑Ô∏è Features categoriche: {len(categorical_features)}\")\n",
        "\n",
        "if categorical_features:\n",
        "    print(\"\\nüìù Features categoriche:\")\n",
        "    for feature in categorical_features:\n",
        "        unique_vals = X_train[feature].nunique()\n",
        "        print(f\"   - {feature}: {unique_vals} valori unici\")\n",
        "\n",
        "# Controllo distribuzione classi\n",
        "class_distribution = y_train.value_counts(normalize=True) * 100\n",
        "print(f\"\\nüìä Distribuzione classi (Training):\")\n",
        "for class_val, percentage in class_distribution.items():\n",
        "    class_name = \"Guasto\" if class_val == 1 else \"Normale\"\n",
        "    print(f\"   {class_name} (classe {class_val}): {percentage:.2f}%\")\n",
        "\n",
        "# Determina se il dataset √® sbilanciato\n",
        "minority_class_pct = min(class_distribution.values)\n",
        "is_imbalanced = minority_class_pct < 30\n",
        "\n",
        "if is_imbalanced:\n",
        "    print(f\"‚ö†Ô∏è Dataset sbilanciato rilevato (classe minoritaria: {minority_class_pct:.2f}%)\")\n",
        "    print(\"   ‚Üí SMOTE sar√† applicato durante il training\")\n",
        "else:\n",
        "    print(f\"‚úÖ Dataset bilanciato (classe minoritaria: {minority_class_pct:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing delle features categoriche se presenti\n",
        "if categorical_features:\n",
        "    print(\"üîÑ Encoding features categoriche...\")\n",
        "    label_encoders = {}\n",
        "    \n",
        "    for feature in categorical_features:\n",
        "        le = LabelEncoder()\n",
        "        # Fit su tutti i dati per evitare problemi con nuove categorie\n",
        "        all_values = pd.concat([X_train[feature], X_test[feature]]).fillna('Unknown')\n",
        "        le.fit(all_values)\n",
        "        \n",
        "        X_train[feature] = le.transform(X_train[feature].fillna('Unknown'))\n",
        "        X_test[feature] = le.transform(X_test[feature].fillna('Unknown'))\n",
        "        \n",
        "        label_encoders[feature] = le\n",
        "        print(f\"   ‚úÖ {feature}: {len(le.classes_)} categorie\")\n",
        "    \n",
        "    # Salvataggio encoders\n",
        "    os.makedirs('data/models', exist_ok=True)\n",
        "    joblib.dump(label_encoders, 'data/models/label_encoders.pkl')\n",
        "    print(\"üíæ Label encoders salvati\")\n",
        "\n",
        "# Gestione valori mancanti nelle features numeriche\n",
        "print(\"\\nüîç Controllo valori mancanti:\")\n",
        "missing_train = X_train.isnull().sum()\n",
        "missing_test = X_test.isnull().sum()\n",
        "\n",
        "if missing_train.sum() > 0 or missing_test.sum() > 0:\n",
        "    print(\"‚ö†Ô∏è Valori mancanti rilevati - applicazione strategia di riempimento\")\n",
        "    # Riempi con la mediana per le features numeriche\n",
        "    for feature in numeric_features:\n",
        "        if X_train[feature].isnull().sum() > 0:\n",
        "            median_val = X_train[feature].median()\n",
        "            X_train[feature].fillna(median_val, inplace=True)\n",
        "            X_test[feature].fillna(median_val, inplace=True)\n",
        "            print(f\"   ‚úÖ {feature}: riempito con mediana ({median_val:.2f})\")\n",
        "else:\n",
        "    print(\"‚úÖ Nessun valore mancante\")\n",
        "\n",
        "# Standardizzazione features numeriche\n",
        "print(\"\\nüìè Standardizzazione features numeriche...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Salvataggio scaler\n",
        "joblib.dump(scaler, 'data/models/scaler.pkl')\n",
        "print(\"üíæ Scaler salvato\")\n",
        "\n",
        "# Conversione in DataFrame per mantenere nomi delle colonne\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "print(f\"üìä Shape finale - Train: {X_train_scaled.shape}, Test: {X_test_scaled.shape}\")\n",
        "\n",
        "# Controllo finale\n",
        "print(\"\\nüîç Controllo finale dati:\")\n",
        "print(f\"   Valori infiniti (train): {np.isinf(X_train_scaled.values).sum()}\")\n",
        "print(f\"   Valori NaN (train): {np.isnan(X_train_scaled.values).sum()}\")\n",
        "print(f\"   Range valori (train): [{X_train_scaled.values.min():.3f}, {X_train_scaled.values.max():.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Selection con SelectKBest\n",
        "print(\"üéØ Feature Selection...\")\n",
        "\n",
        "# Selezione delle top K features pi√π significative\n",
        "k_best = min(15, X_train_scaled.shape[1])  # Massimo 15 features o tutte se meno di 15\n",
        "selector = SelectKBest(score_func=f_classif, k=k_best)\n",
        "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "# Ottieni nomi delle features selezionate\n",
        "selected_features = X_train_scaled.columns[selector.get_support()].tolist()\n",
        "feature_scores = selector.scores_[selector.get_support()]\n",
        "\n",
        "print(f\"‚úÖ Selezionate {len(selected_features)} features su {X_train_scaled.shape[1]}\")\n",
        "\n",
        "# Creazione DataFrame per feature importance\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Score': feature_scores\n",
        "}).sort_values('Score', ascending=False)\n",
        "\n",
        "print(f\"\\nüèÜ Top {min(10, len(selected_features))} features pi√π importanti:\")\n",
        "for i, (_, row) in enumerate(feature_importance_df.head(10).iterrows()):\n",
        "    print(f\"   {i+1:2d}. {row['Feature']:<30} (Score: {row['Score']:.2f})\")\n",
        "\n",
        "# Visualizzazione feature importance\n",
        "plt.figure(figsize=(12, 6))\n",
        "top_features = feature_importance_df.head(10)\n",
        "plt.barh(range(len(top_features)), top_features['Score'], color='skyblue')\n",
        "plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.title('Top 10 Features pi√π Importanti (SelectKBest F-Score)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Salvataggio feature selector\n",
        "joblib.dump(selector, 'data/models/feature_selector.pkl')\n",
        "print(\"\\nüíæ Feature selector salvato\")\n",
        "\n",
        "# Salvataggio lista features selezionate\n",
        "with open('data/models/selected_features.json', 'w') as f:\n",
        "    json.dump(selected_features, f, indent=2)\n",
        "print(\"üíæ Lista features selezionate salvata\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Definizione e Training Modelli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definizione modelli da testare (secondo le indicazioni del PDF)\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'Decision Tree': DecisionTreeClassifier(\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'KNN': KNeighborsClassifier(\n",
        "        n_neighbors=5,\n",
        "        weights='distance'\n",
        "    ),\n",
        "    'SVM': SVC(\n",
        "        kernel='rbf',\n",
        "        probability=True,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    ),\n",
        "    'Logistic Regression': LogisticRegression(\n",
        "        random_state=42,\n",
        "        max_iter=1000,\n",
        "        class_weight='balanced'\n",
        "    ),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=6,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# Aggiungi XGBoost se disponibile\n",
        "if XGBOOST_AVAILABLE:\n",
        "    models['XGBoost'] = xgb.XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "\n",
        "print(f\"ü§ñ Modelli da testare ({len(models)}): {list(models.keys())}\")\n",
        "\n",
        "# Setup per cross-validation\n",
        "cv_folds = 5\n",
        "cv_strategy = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Storage per risultati\n",
        "model_results = {}\n",
        "trained_models = {}\n",
        "\n",
        "print(f\"\\nüîÑ Configurazione Cross-Validation: {cv_folds}-fold stratificato\")\n",
        "print(f\"üìä Dataset bilanciamento: {'SMOTE applicato' if is_imbalanced else 'Nessun bilanciamento necessario'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training e valutazione modelli\n",
        "print(\"üöÄ Inizio training modelli...\\n\")\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"üîÑ Training {model_name}...\")\n",
        "    \n",
        "    try:\n",
        "        start_time = datetime.now()\n",
        "        \n",
        "        # Crea pipeline con SMOTE se dataset sbilanciato\n",
        "        if is_imbalanced:\n",
        "            pipeline = ImbPipeline([\n",
        "                ('smote', SMOTE(random_state=42)),\n",
        "                ('classifier', model)\n",
        "            ])\n",
        "        else:\n",
        "            pipeline = model\n",
        "        \n",
        "        # Cross-validation\n",
        "        print(\"   üìä Esecuzione cross-validation...\")\n",
        "        cv_scores = cross_val_score(\n",
        "            pipeline, X_train_selected, y_train, \n",
        "            cv=cv_strategy, scoring='roc_auc', n_jobs=-1\n",
        "        )\n",
        "        \n",
        "        # Training su tutto il training set\n",
        "        print(\"   üèãÔ∏è Training su training set completo...\")\n",
        "        pipeline.fit(X_train_selected, y_train)\n",
        "        \n",
        "        # Predizioni\n",
        "        print(\"   üîÆ Generazione predizioni...\")\n",
        "        y_pred = pipeline.predict(X_test_selected)\n",
        "        y_pred_proba = pipeline.predict_proba(X_test_selected)[:, 1]\n",
        "        \n",
        "        # Calcolo metriche complete\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        \n",
        "        # Tempo di training\n",
        "        training_time = (datetime.now() - start_time).total_seconds()\n",
        "        \n",
        "        # Storage risultati\n",
        "        model_results[model_name] = {\n",
        "            'cv_scores': cv_scores,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std(),\n",
        "            'test_accuracy': accuracy,\n",
        "            'test_precision': precision,\n",
        "            'test_recall': recall,\n",
        "            'test_f1': f1,\n",
        "            'test_roc_auc': roc_auc,\n",
        "            'predictions': y_pred,\n",
        "            'probabilities': y_pred_proba,\n",
        "            'training_time': training_time\n",
        "        }\n",
        "        \n",
        "        trained_models[model_name] = pipeline\n",
        "        \n",
        "        # Output risultati\n",
        "        print(f\"   ‚úÖ CV AUC: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")\n",
        "        print(f\"   ‚úÖ Test Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"   ‚úÖ Test Precision: {precision:.4f}\")\n",
        "        print(f\"   ‚úÖ Test Recall: {recall:.4f}\")\n",
        "        print(f\"   ‚úÖ Test F1-Score: {f1:.4f}\")\n",
        "        print(f\"   ‚úÖ Test AUC: {roc_auc:.4f}\")\n",
        "        print(f\"   ‚è±Ô∏è Training time: {training_time:.2f}s\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Errore durante training: {str(e)}\")\n",
        "        continue\n",
        "    \n",
        "    print()\n",
        "\n",
        "print(\"üéâ Training completato per tutti i modelli!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Confronto Performance Modelli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creazione DataFrame per confronto risultati\n",
        "results_data = []\n",
        "for model_name, results in model_results.items():\n",
        "    results_data.append({\n",
        "        'Model': model_name,\n",
        "        'CV_AUC_Mean': results['cv_mean'],\n",
        "        'CV_AUC_Std': results['cv_std'],\n",
        "        'Test_Accuracy': results['test_accuracy'],\n",
        "        'Test_Precision': results['test_precision'],\n",
        "        'Test_Recall': results['test_recall'],\n",
        "        'Test_F1': results['test_f1'],\n",
        "        'Test_AUC': results['test_roc_auc'],\n",
        "        'Training_Time': results['training_time']\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "# Ordina per performance AUC su test set\n",
        "results_df = results_df.sort_values('Test_AUC', ascending=False)\n",
        "\n",
        "print(\"üìä RISULTATI CONFRONTO MODELLI:\")\n",
        "print(\"=\" * 100)\n",
        "print(f\"{'Modello':<18} {'CV AUC':<13} {'Accuracy':<9} {'Precision':<10} {'Recall':<8} {'F1-Score':<9} {'Test AUC':<9} {'Time(s)':<8} {'Rank'}\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "for i, (_, row) in enumerate(results_df.iterrows()):\n",
        "    cv_score = f\"{row['CV_AUC_Mean']:.3f}¬±{row['CV_AUC_Std']:.2f}\"\n",
        "    accuracy = f\"{row['Test_Accuracy']:.4f}\"\n",
        "    precision = f\"{row['Test_Precision']:.4f}\"\n",
        "    recall = f\"{row['Test_Recall']:.4f}\"\n",
        "    f1_score = f\"{row['Test_F1']:.4f}\"\n",
        "    test_auc = f\"{row['Test_AUC']:.4f}\"\n",
        "    time_s = f\"{row['Training_Time']:.1f}\"\n",
        "    rank = f\"#{i+1}\"\n",
        "    \n",
        "    print(f\"{row['Model']:<18} {cv_score:<13} {accuracy:<9} {precision:<10} {recall:<8} {f1_score:<9} {test_auc:<9} {time_s:<8} {rank}\")\n",
        "\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Identifica il miglior modello\n",
        "best_model_name = results_df.iloc[0]['Model']\n",
        "print(f\"\\nüèÜ MIGLIOR MODELLO: {best_model_name}\")\n",
        "print(f\"   üìä Test AUC: {results_df.iloc[0]['Test_AUC']:.4f}\")\n",
        "print(f\"   üéØ Test F1-Score: {results_df.iloc[0]['Test_F1']:.4f}\")\n",
        "print(f\"   ‚öñÔ∏è Test Precision: {results_df.iloc[0]['Test_Precision']:.4f}\")\n",
        "print(f\"   üîç Test Recall: {results_df.iloc[0]['Test_Recall']:.4f}\")\n",
        "\n",
        "# Salvataggio risultati\n",
        "results_df.to_csv('data/models/model_comparison_results.csv', index=False)\n",
        "print(\"\\nüíæ Risultati salvati in 'data/models/model_comparison_results.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Visualizzazioni Performance"
      ]
    },
    {
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Curve ROC e Analisi Performance\n",
        "### Visualizzazione dettagliata delle performance per ogni modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizzazione Curve ROC per tutti i modelli\n",
        "plt.figure(figsize=(12, 8))\n",
        "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink']\n",
        "\n",
        "for i, (model_name, results) in enumerate(model_results.items()):\n",
        "    # Calcola curve ROC\n",
        "    fpr, tpr, _ = roc_curve(y_test, results['probabilities'])\n",
        "    auc_score = results['test_roc_auc']\n",
        "    \n",
        "    plt.plot(fpr, tpr, color=colors[i % len(colors)], lw=2, \n",
        "             label=f'{model_name} (AUC = {auc_score:.3f})')\n",
        "\n",
        "# Linea diagonale random\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('Curve ROC - Confronto Modelli', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('data/models/roc_curves_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Curve ROC salvate in 'data/models/roc_curves_comparison.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Matrice di Confusione - Miglior Modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrice di confusione per il miglior modello\n",
        "best_predictions = model_results[best_model_name]['predictions']\n",
        "cm = confusion_matrix(y_test, best_predictions)\n",
        "\n",
        "# Visualizzazione matrice di confusione\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['Normale', 'Guasto'],\n",
        "            yticklabels=['Normale', 'Guasto'])\n",
        "plt.title(f'Matrice di Confusione - {best_model_name}', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Classe Reale', fontsize=12)\n",
        "plt.xlabel('Classe Predetta', fontsize=12)\n",
        "\n",
        "# Aggiungi statistiche\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "\n",
        "plt.figtext(0.02, 0.02, \n",
        "           f'Specificity: {specificity:.3f}\\nSensitivity: {sensitivity:.3f}\\n'\n",
        "           f'True Negatives: {tn}\\nFalse Positives: {fp}\\n'\n",
        "           f'False Negatives: {fn}\\nTrue Positives: {tp}',\n",
        "           fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('data/models/confusion_matrix_best_model.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Analisi Matrice di Confusione - {best_model_name}:\")\n",
        "print(f\"   True Negatives:  {tn:4d} (predetto normale, realmente normale)\")\n",
        "print(f\"   False Positives: {fp:4d} (predetto guasto, realmente normale)\")\n",
        "print(f\"   False Negatives: {fn:4d} (predetto normale, realmente guasto) ‚ùå CRITICO\")\n",
        "print(f\"   True Positives:  {tp:4d} (predetto guasto, realmente guasto)\")\n",
        "print(f\"   Specificity:     {specificity:.3f} (capacit√† di identificare i non-guasti)\")\n",
        "print(f\"   Sensitivity:     {sensitivity:.3f} (capacit√† di identificare i guasti)\")\n",
        "\n",
        "if fn > 0:\n",
        "    print(f\"\\n‚ö†Ô∏è ATTENZIONE: {fn} falsi negativi rilevati!\")\n",
        "    print(\"   I falsi negativi sono critici nella manutenzione predittiva\")\n",
        "    print(\"   Significano guasti non previsti che potrebbero causare downtime\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Ottimizzazione Iperparametri - Miglior Modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ottimizzazione iperparametri per il miglior modello\n",
        "print(f\"üîß Ottimizzazione iperparametri per {best_model_name}...\")\n",
        "\n",
        "# Definisci griglie di parametri per diversi modelli\n",
        "param_grids = {\n",
        "    'Random Forest': {\n",
        "        'classifier__n_estimators': [100, 200, 300],\n",
        "        'classifier__max_depth': [10, 15, 20, None],\n",
        "        'classifier__min_samples_split': [2, 5, 10],\n",
        "        'classifier__min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'classifier__n_estimators': [100, 200, 300],\n",
        "        'classifier__max_depth': [3, 6, 9],\n",
        "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
        "        'classifier__subsample': [0.8, 0.9, 1.0]\n",
        "    },\n",
        "    'SVM': {\n",
        "        'classifier__C': [0.1, 1, 10, 100],\n",
        "        'classifier__gamma': ['scale', 'auto', 0.001, 0.01],\n",
        "        'classifier__kernel': ['rbf', 'poly']\n",
        "    },\n",
        "    'Gradient Boosting': {\n",
        "        'classifier__n_estimators': [100, 200, 300],\n",
        "        'classifier__max_depth': [3, 6, 9],\n",
        "        'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
        "        'classifier__subsample': [0.8, 0.9, 1.0]\n",
        "    },\n",
        "    'Logistic Regression': {\n",
        "        'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
        "        'classifier__penalty': ['l1', 'l2'],\n",
        "        'classifier__solver': ['liblinear', 'saga']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Ottimizzazione per il miglior modello\n",
        "if best_model_name in param_grids:\n",
        "    best_pipeline = trained_models[best_model_name]\n",
        "    param_grid = param_grids[best_model_name]\n",
        "    \n",
        "    # Se il modello usa SMOTE, adatta i nomi dei parametri\n",
        "    if is_imbalanced:\n",
        "        param_grid = param_grid\n",
        "    else:\n",
        "        # Rimuovi 'classifier__' se non usa pipeline\n",
        "        param_grid = {k.replace('classifier__', ''): v for k, v in param_grid.items()}\n",
        "    \n",
        "    print(f\"   üîç Ricerca iperparametri ottimali...\")\n",
        "    print(f\"   üìä Parametri da testare: {sum(len(v) for v in param_grid.values())} combinazioni\")\n",
        "    \n",
        "    # GridSearchCV con cross-validation\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=best_pipeline,\n",
        "        param_grid=param_grid,\n",
        "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
        "        scoring='roc_auc',\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # Esegui ricerca (su un subset per velocit√† se dataset √® grande)\n",
        "    if X_train_selected.shape[0] > 5000:\n",
        "        # Usa un subset per velocizzare la ricerca\n",
        "        sample_size = 3000\n",
        "        indices = np.random.choice(X_train_selected.shape[0], sample_size, replace=False)\n",
        "        X_grid = X_train_selected[indices]\n",
        "        y_grid = y_train.iloc[indices]\n",
        "        print(f\"   üìù Utilizzando subset di {sample_size} campioni per velocizzare la ricerca\")\n",
        "    else:\n",
        "        X_grid = X_train_selected\n",
        "        y_grid = y_train\n",
        "    \n",
        "    start_time = datetime.now()\n",
        "    grid_search.fit(X_grid, y_grid)\n",
        "    search_time = (datetime.now() - start_time).total_seconds()\n",
        "    \n",
        "    print(f\"   ‚úÖ Ricerca completata in {search_time:.1f}s\")\n",
        "    print(f\"   üèÜ Miglior score CV: {grid_search.best_score_:.4f}\")\n",
        "    print(f\"   üéØ Miglior parametri: {grid_search.best_params_}\")\n",
        "    \n",
        "    # Valuta il modello ottimizzato sul test set\n",
        "    optimized_model = grid_search.best_estimator_\n",
        "    y_pred_opt = optimized_model.predict(X_test_selected)\n",
        "    y_pred_proba_opt = optimized_model.predict_proba(X_test_selected)[:, 1]\n",
        "    \n",
        "    # Calcola metriche ottimizzate\n",
        "    opt_accuracy = accuracy_score(y_test, y_pred_opt)\n",
        "    opt_precision = precision_score(y_test, y_pred_opt)\n",
        "    opt_recall = recall_score(y_test, y_pred_opt)\n",
        "    opt_f1 = f1_score(y_test, y_pred_opt)\n",
        "    opt_roc_auc = roc_auc_score(y_test, y_pred_proba_opt)\n",
        "    \n",
        "    print(f\"\\nüìä CONFRONTO PERFORMANCE:\")\n",
        "    print(f\"   {'Metrica':<15} {'Originale':<10} {'Ottimizzato':<12} {'Miglioramento'}\")\n",
        "    print(f\"   {'-'*50}\")\n",
        "    \n",
        "    orig_results = model_results[best_model_name]\n",
        "    metrics = [\n",
        "        ('Accuracy', orig_results['test_accuracy'], opt_accuracy),\n",
        "        ('Precision', orig_results['test_precision'], opt_precision),\n",
        "        ('Recall', orig_results['test_recall'], opt_recall),\n",
        "        ('F1-Score', orig_results['test_f1'], opt_f1),\n",
        "        ('AUC', orig_results['test_roc_auc'], opt_roc_auc)\n",
        "    ]\n",
        "    \n",
        "    for metric_name, orig_val, opt_val in metrics:\n",
        "        improvement = ((opt_val - orig_val) / orig_val) * 100\n",
        "        improvement_str = f\"{improvement:+.2f}%\"\n",
        "        print(f\"   {metric_name:<15} {orig_val:<10.4f} {opt_val:<12.4f} {improvement_str}\")\n",
        "    \n",
        "    # Salva il modello ottimizzato se migliore\n",
        "    if opt_roc_auc > orig_results['test_roc_auc']:\n",
        "        print(f\"\\n‚úÖ Modello ottimizzato √® migliore! Salvataggio...\")\n",
        "        joblib.dump(optimized_model, 'data/models/best_optimized_model.pkl')\n",
        "        \n",
        "        # Aggiorna i risultati\n",
        "        model_results[f'{best_model_name}_Optimized'] = {\n",
        "            'test_accuracy': opt_accuracy,\n",
        "            'test_precision': opt_precision,\n",
        "            'test_recall': opt_recall,\n",
        "            'test_f1': opt_f1,\n",
        "            'test_roc_auc': opt_roc_auc,\n",
        "            'predictions': y_pred_opt,\n",
        "            'probabilities': y_pred_proba_opt,\n",
        "            'best_params': grid_search.best_params_\n",
        "        }\n",
        "        \n",
        "        final_model = optimized_model\n",
        "        final_model_name = f'{best_model_name}_Optimized'\n",
        "        print(f\"üíæ Modello finale salvato: {final_model_name}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è Modello originale √® migliore, mantenendo quello\")\n",
        "        final_model = trained_models[best_model_name]\n",
        "        final_model_name = best_model_name\n",
        "        \n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Griglia parametri non definita per {best_model_name}\")\n",
        "    final_model = trained_models[best_model_name]\n",
        "    final_model_name = best_model_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Feature Importance - Modello Finale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analisi Feature Importance per il modello finale\n",
        "print(f\"üéØ Analisi Feature Importance - {final_model_name}\")\n",
        "\n",
        "try:\n",
        "    # Estrai il modello dal pipeline se necessario\n",
        "    if hasattr(final_model, 'named_steps'):\n",
        "        # Pipeline con SMOTE\n",
        "        classifier = final_model.named_steps['classifier']\n",
        "    else:\n",
        "        # Modello diretto\n",
        "        classifier = final_model\n",
        "    \n",
        "    # Ottieni feature importance se disponibile\n",
        "    if hasattr(classifier, 'feature_importances_'):\n",
        "        importances = classifier.feature_importances_\n",
        "    elif hasattr(classifier, 'coef_'):\n",
        "        # Per modelli lineari usa i coefficienti assoluti\n",
        "        importances = np.abs(classifier.coef_[0])\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Feature importance non disponibile per questo modello\")\n",
        "        importances = None\n",
        "    \n",
        "    if importances is not None:\n",
        "        # Crea DataFrame per feature importance\n",
        "        feature_imp_df = pd.DataFrame({\n",
        "            'Feature': selected_features,\n",
        "            'Importance': importances\n",
        "        }).sort_values('Importance', ascending=False)\n",
        "        \n",
        "        print(f\"\\nüèÜ Top 10 Features pi√π Importanti:\")\n",
        "        for i, (_, row) in enumerate(feature_imp_df.head(10).iterrows()):\n",
        "            print(f\"   {i+1:2d}. {row['Feature']:<30} {row['Importance']:.4f}\")\n",
        "        \n",
        "        # Visualizzazione feature importance\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        top_features = feature_imp_df.head(15)\n",
        "        \n",
        "        bars = plt.barh(range(len(top_features)), top_features['Importance'], \n",
        "                       color='lightblue', alpha=0.8)\n",
        "        plt.yticks(range(len(top_features)), top_features['Feature'])\n",
        "        plt.xlabel('Feature Importance', fontsize=12)\n",
        "        plt.title(f'Feature Importance - {final_model_name}', fontsize=14, fontweight='bold')\n",
        "        plt.gca().invert_yaxis()\n",
        "        \n",
        "        # Aggiungi valori sulle barre\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            plt.text(width + 0.001, bar.get_y() + bar.get_height()/2,\n",
        "                    f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('data/models/feature_importance_final_model.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # Salva feature importance\n",
        "        feature_imp_df.to_csv('data/models/feature_importance.csv', index=False)\n",
        "        print(\"\\nüíæ Feature importance salvata in 'data/models/feature_importance.csv'\")\n",
        "        \n",
        "        # Analisi gruppi di features\n",
        "        print(f\"\\nüìä Analisi Gruppi Features:\")\n",
        "        \n",
        "        # Categorizza le features\n",
        "        sensor_features = [f for f in selected_features if any(x in f.lower() for x in ['temperature', 'vibration', 'sound', 'pressure'])]\n",
        "        maintenance_features = [f for f in selected_features if any(x in f.lower() for x in ['maintenance', 'operational', 'last'])]\n",
        "        failure_features = [f for f in selected_features if any(x in f.lower() for x in ['failure', 'error', 'ai'])]\n",
        "        level_features = [f for f in selected_features if any(x in f.lower() for x in ['level', 'oil', 'coolant'])]\n",
        "        \n",
        "        groups = {\n",
        "            'Sensori': sensor_features,\n",
        "            'Manutenzione': maintenance_features,\n",
        "            'Guasti/Errori': failure_features,\n",
        "            'Livelli': level_features\n",
        "        }\n",
        "        \n",
        "        for group_name, group_features in groups.items():\n",
        "            if group_features:\n",
        "                group_importance = feature_imp_df[feature_imp_df['Feature'].isin(group_features)]['Importance'].sum()\n",
        "                print(f\"   {group_name:<15}: {group_importance:.4f} ({len(group_features)} features)\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Errore nell'analisi feature importance: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Test con Input Realistici\n",
        "### Verifica del modello con 3 esempi inventati ma realistici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test con 3 input realistici secondo le richieste del progetto\n",
        "print(\"üß™ TEST MODELLO CON INPUT REALISTICI\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Definisci 3 scenari di test realistici\n",
        "test_scenarios = [\n",
        "    {\n",
        "        'name': 'Scenario 1: Macchina in Condizioni Critiche',\n",
        "        'description': 'CNC_Mill con parametri che indicano possibile guasto imminente',\n",
        "        'data': {\n",
        "            'Installation_Year': 2018,\n",
        "            'Operational_Hours': 35000,\n",
        "            'Temperature_C': 85.5,\n",
        "            'Vibration_mms': 8.2,\n",
        "            'Sound_dB': 78.5,\n",
        "            'Oil_Level_pct': 15.2,\n",
        "            'Coolant_Level_pct': 22.1,\n",
        "            'Power_Consumption_kW': 145.8,\n",
        "            'Last_Maintenance_Days_Ago': 180,\n",
        "            'Maintenance_History_Count': 3,\n",
        "            'Failure_History_Count': 2,\n",
        "            'AI_Supervision': 1,\n",
        "            'Error_Codes_Last_30_Days': 15,\n",
        "            'AI_Override_Events': 8,\n",
        "            'Coolant_Flow_L_min': 2.1  # Specifico per CNC_Mill\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'Scenario 2: Macchina in Buone Condizioni',\n",
        "        'description': 'Robot_Arm con parametri ottimali',\n",
        "        'data': {\n",
        "            'Installation_Year': 2022,\n",
        "            'Operational_Hours': 8500,\n",
        "            'Temperature_C': 45.2,\n",
        "            'Vibration_mms': 2.1,\n",
        "            'Sound_dB': 52.3,\n",
        "            'Oil_Level_pct': 85.7,\n",
        "            'Coolant_Level_pct': 78.9,\n",
        "            'Power_Consumption_kW': 67.2,\n",
        "            'Last_Maintenance_Days_Ago': 25,\n",
        "            'Maintenance_History_Count': 8,\n",
        "            'Failure_History_Count': 0,\n",
        "            'AI_Supervision': 1,\n",
        "            'Error_Codes_Last_30_Days': 1,\n",
        "            'AI_Override_Events': 0\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'name': 'Scenario 3: Macchina con Segnali Misti',\n",
        "        'description': 'Hydraulic_Press con alcuni parametri preoccupanti',\n",
        "        'data': {\n",
        "            'Installation_Year': 2020,\n",
        "            'Operational_Hours': 18750,\n",
        "            'Temperature_C': 68.4,\n",
        "            'Vibration_mms': 5.8,\n",
        "            'Sound_dB': 65.2,\n",
        "            'Oil_Level_pct': 45.3,\n",
        "            'Coolant_Level_pct': 62.8,\n",
        "            'Power_Consumption_kW': 98.7,\n",
        "            'Last_Maintenance_Days_Ago': 95,\n",
        "            'Maintenance_History_Count': 5,\n",
        "            'Failure_History_Count': 1,\n",
        "            'AI_Supervision': 1,\n",
        "            'Error_Codes_Last_30_Days': 6,\n",
        "            'AI_Override_Events': 3,\n",
        "            'Hydraulic_Pressure_bar': 185.6  # Specifico per Hydraulic_Press\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Prepara i dati per le predizioni\n",
        "test_results = []\n",
        "\n",
        "for i, scenario in enumerate(test_scenarios, 1):\n",
        "    print(f\"\\nüîç {scenario['name']}\")\n",
        "    print(f\"   üìù {scenario['description']}\")\n",
        "    \n",
        "    try:\n",
        "        # Crea DataFrame con le features disponibili\n",
        "        # Riempie le features mancanti con valori medi dal training set\n",
        "        test_data_dict = {}\n",
        "        \n",
        "        for feature in X_train.columns:\n",
        "            if feature in scenario['data']:\n",
        "                test_data_dict[feature] = scenario['data'][feature]\n",
        "            else:\n",
        "                # Usa la media del training set per features mancanti\n",
        "                test_data_dict[feature] = X_train[feature].mean()\n",
        "        \n",
        "        # Crea DataFrame di test\n",
        "        test_input = pd.DataFrame([test_data_dict])\n",
        "        \n",
        "        # Applica le stesse trasformazioni del training\n",
        "        test_input_scale